{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3277 images belonging to 9 classes.\n",
      "Found 500 images belonging to 8 classes.\n",
      "Found 1000 images belonging to 1 classes.\n",
      "Found 3277 images belonging to 9 classes.\n",
      "Found 500 images belonging to 8 classes.\n",
      "Found 1000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Rather than importing everything manually, we'll make things easy\n",
    "#   and load them all in utils.py, and just import them from there.\n",
    "%matplotlib inline\n",
    "import utils;\n",
    "from utils import *\n",
    "import time\n",
    "from __future__ import division, print_function\n",
    "import sys\n",
    "sys.path.insert(1, '/home/mh/opencv-master/build/lib/python3')\n",
    "import cv2\n",
    "import glob\n",
    "from keras.optimizers import Adadelta\n",
    "\n",
    "data_path = '/home/mh/ws/fish_challenge/input/'\n",
    "model_path = '/home/mh/ws/fish_challenge/input/models/'\n",
    "batch_size=32\n",
    "\n",
    "batches = get_batches(data_path+'train', batch_size=batch_size)\n",
    "val_batches = get_batches(data_path+'valid', batch_size=batch_size*2, shuffle=False)\n",
    "test_filenames = get_batches(data_path+'test', batch_size=batch_size).filenames\n",
    "\n",
    "(val_classes, trn_classes, val_labels, trn_labels, \n",
    "    val_filenames, filenames, test_filenames) = get_classes(data_path)\n",
    "\n",
    "raw_filenames = [f.split('/')[-1] for f in filenames]\n",
    "raw_test_filenames = [f.split('/')[-1] for f in test_filenames]\n",
    "raw_val_filenames = [f.split('/')[-1] for f in val_filenames]\n",
    "\n",
    "## Load data.\n",
    "trn_data = load_array(model_path+'train_data.bc')\n",
    "val_data = load_array(model_path+'valid_data.bc')\n",
    "trn_labels = load_array(model_path+'trn_labels.bc')\n",
    "val_labels = load_array(model_path+'val_labels.bc')\n",
    "val_labels = onehot(val_labels)\n",
    "trn_labels = onehot(trn_labels)\n",
    "\n",
    "test_data = load_array(model_path+'test_data.bc')\n",
    "test_data = test_data.transpose((0,3,1,2))\n",
    "\n",
    "from vgg16bn import Vgg16BN\n",
    "model = vgg_ft_bn(8)\n",
    "\n",
    "model.compile(optimizer=Adam(1e-3),\n",
    "       loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.load_weights(data_path+'results/ft1.h5')\n",
    "\n",
    "conv_layers,fc_layers = split_at(model, Convolution2D)\n",
    "conv_model = Sequential(conv_layers)\n",
    "#load features\n",
    "conv_feat = load_array(data_path+'results/conv_feat.dat')\n",
    "conv_val_feat = load_array(data_path+'results/conv_val_feat.dat')\n",
    "conv_test_feat = load_array(data_path+'results/conv_test_feat.dat')\n",
    "\n",
    "def get_bn_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        BatchNormalization(axis=1),\n",
    "        Dropout(p/4),\n",
    "        Flatten(),\n",
    "        Dense(512,activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p/2),\n",
    "        Dense(512,activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p/2),\n",
    "        Dense(8,activation='softmax')\n",
    "    ]\n",
    "\n",
    "p=0.6\n",
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "bn_model.load_weights(data_path+'models/conv_512_6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 3, ?, ?)\n",
      "(?, 2, 4)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The `get_output_shape_for` method of layer \"roipooling_4\"\" should return one shape tuple per output tensor of the layer. Found: [(None, 3, None, None), (None, 2, 4)]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9e9d457fca78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_roi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mout_roi_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRoiPooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooling_regions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rois\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0min_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_roi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0min_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_roi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_roi_pool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mh/.local/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minbound_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0;31m# This will call layer.build() if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_inbound_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minbound_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m             \u001b[0;31m# Outputs were already computed when calling self.add_inbound_node.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mh/.local/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36madd_inbound_node\u001b[0;34m(self, inbound_layers, node_indices, tensor_indices)\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;31m# creating the node automatically updates self.inbound_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0;31m# as well as outbound_nodes on inbound layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mNode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minbound_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_output_shape_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mh/.local/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mcreate_node\u001b[0;34m(cls, outbound_layer, inbound_layers, node_indices, tensor_indices)\u001b[0m\n\u001b[1;32m    184\u001b[0m                              \u001b[0;34m'\"\" should return one shape tuple per '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                              \u001b[0;34m'output tensor of the layer. Found: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                              str(output_shapes))\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             raise ValueError('The `compute_mask` method of layer \"' +\n",
      "\u001b[0;31mValueError\u001b[0m: The `get_output_shape_for` method of layer \"roipooling_4\"\" should return one shape tuple per output tensor of the layer. Found: [(None, 3, None, None), (None, 2, 4)]"
     ]
    }
   ],
   "source": [
    "from SpatialPyramidPooling import SpatialPyramidPooling\n",
    "from RoiPooling import RoiPooling\n",
    "\n",
    "pooling_regions = [1, 2, 4]\n",
    "num_rois = 2\n",
    "num_channels = 3\n",
    "\n",
    "# if dim_ordering == 'tf':\n",
    "#     in_img = Input(shape=(None, None, num_channels))\n",
    "# elif dim_ordering == 'th':\n",
    "in_img = Input(shape=(num_channels, None, None))\n",
    "\n",
    "in_roi = Input(shape=(num_rois, 4))\n",
    "print(in_img.shape)\n",
    "print(in_roi.shape)\n",
    "out_roi_pool = RoiPooling(pooling_regions, num_rois)([in_img, in_roi])\n",
    "\n",
    "model = Model([in_img, in_roi], out_roi_pool)\n",
    "\n",
    "if dim_ordering == 'th':\n",
    "    X_img = np.random.rand(1, num_channels, img_size, img_size)\n",
    "    row_length = [float(X_img.shape[2]) / i for i in pooling_regions]\n",
    "    col_length = [float(X_img.shape[3]) / i for i in pooling_regions]\n",
    "elif dim_ordering == 'tf':\n",
    "    X_img = np.random.rand(1, img_size, img_size, num_channels)\n",
    "    row_length = [float(X_img.shape[1]) / i for i in pooling_regions]\n",
    "    col_length = [float(X_img.shape[2]) / i for i in pooling_regions]\n",
    "\n",
    "X_roi = np.array([[0, 0, img_size / 1, img_size / 1],\n",
    "                  [0, 0, img_size / 2, img_size / 2]])\n",
    "\n",
    "X_roi = np.reshape(X_roi, (1, num_rois, 4))\n",
    "\n",
    "Y = model.predict([X_img, X_roi])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
