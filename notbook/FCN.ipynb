{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3277 images belonging to 8 classes.\n",
      "Found 500 images belonging to 8 classes.\n",
      "Found 1000 images belonging to 1 classes.\n",
      "Found 3277 images belonging to 8 classes.\n",
      "Found 500 images belonging to 8 classes.\n",
      "Found 1000 images belonging to 1 classes.\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 3, 224, 224)   0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_1 (ZeroPadding2D)  (None, 3, 226, 226)   0           lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 64, 224, 224)  1792        zeropadding2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_2 (ZeroPadding2D)  (None, 64, 226, 226)  0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 64, 224, 224)  36928       zeropadding2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 64, 112, 112)  0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_3 (ZeroPadding2D)  (None, 64, 114, 114)  0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 128, 112, 112) 73856       zeropadding2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_4 (ZeroPadding2D)  (None, 128, 114, 114) 0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 128, 112, 112) 147584      zeropadding2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 128, 56, 56)   0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_5 (ZeroPadding2D)  (None, 128, 58, 58)   0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 256, 56, 56)   295168      zeropadding2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_6 (ZeroPadding2D)  (None, 256, 58, 58)   0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 256, 56, 56)   590080      zeropadding2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_7 (ZeroPadding2D)  (None, 256, 58, 58)   0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 256, 56, 56)   590080      zeropadding2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 256, 28, 28)   0           convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_8 (ZeroPadding2D)  (None, 256, 30, 30)   0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 512, 28, 28)   1180160     zeropadding2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_9 (ZeroPadding2D)  (None, 512, 30, 30)   0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 512, 28, 28)   2359808     zeropadding2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_10 (ZeroPadding2D) (None, 512, 30, 30)   0           convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 512, 28, 28)   2359808     zeropadding2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 512, 14, 14)   0           convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_11 (ZeroPadding2D) (None, 512, 16, 16)   0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_12 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_13 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 512, 7, 7)     0           convolution2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 25088)         0           maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 4096)          102764544   flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 4096)          16384       dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 4096)          0           batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 4096)          16781312    dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNorma (None, 4096)          16384       dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 4096)          0           batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 8)             32776       dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 134,326,088\n",
      "Trainable params: 32,776\n",
      "Non-trainable params: 134,293,312\n",
      "____________________________________________________________________________________________________\n",
      "lambda_1\n",
      "zeropadding2d_1\n",
      "convolution2d_1\n",
      "zeropadding2d_2\n",
      "convolution2d_2\n",
      "maxpooling2d_1\n",
      "zeropadding2d_3\n",
      "convolution2d_3\n",
      "zeropadding2d_4\n",
      "convolution2d_4\n",
      "maxpooling2d_2\n",
      "zeropadding2d_5\n",
      "convolution2d_5\n",
      "zeropadding2d_6\n",
      "convolution2d_6\n",
      "zeropadding2d_7\n",
      "convolution2d_7\n",
      "maxpooling2d_3\n",
      "zeropadding2d_8\n",
      "convolution2d_8\n",
      "zeropadding2d_9\n",
      "convolution2d_9\n",
      "zeropadding2d_10\n",
      "convolution2d_10\n",
      "maxpooling2d_4\n",
      "zeropadding2d_11\n",
      "convolution2d_11\n",
      "zeropadding2d_12\n",
      "convolution2d_12\n",
      "zeropadding2d_13\n",
      "convolution2d_13\n",
      "maxpooling2d_5\n",
      "flatten_1\n",
      "dense_1\n",
      "batchnormalization_1\n",
      "dropout_1\n",
      "dense_2\n",
      "batchnormalization_2\n",
      "dropout_2\n",
      "dense_4\n"
     ]
    }
   ],
   "source": [
    "# Rather than importing everything manually, we'll make things easy\n",
    "#   and load them all in utils.py, and just import them from there.\n",
    "%matplotlib inline\n",
    "import utils;\n",
    "from utils import *\n",
    "import time\n",
    "from __future__ import division, print_function\n",
    "import sys\n",
    "sys.path.insert(1, '/home/mh/opencv-master/build/lib/python3')\n",
    "import cv2\n",
    "import glob\n",
    "from keras.optimizers import Adadelta\n",
    "\n",
    "data_path = '/home/mh/ws/fish_challenge/input/'\n",
    "model_path = '/home/mh/ws/fish_challenge/input/models/'\n",
    "batch_size=32\n",
    "\n",
    "batches = get_batches(data_path+'train', batch_size=batch_size)\n",
    "val_batches = get_batches(data_path+'valid', batch_size=batch_size*2, shuffle=False)\n",
    "test_filenames = get_batches(data_path+'test', batch_size=batch_size).filenames\n",
    "\n",
    "(val_classes, trn_classes, val_labels, trn_labels, \n",
    "    val_filenames, filenames, test_filenames) = get_classes(data_path)\n",
    "\n",
    "raw_filenames = [f.split('/')[-1] for f in filenames]\n",
    "raw_test_filenames = [f.split('/')[-1] for f in test_filenames]\n",
    "raw_val_filenames = [f.split('/')[-1] for f in val_filenames]\n",
    "\n",
    "## Load data.\n",
    "trn_data = load_array(model_path+'train_data.bc')\n",
    "val_data = load_array(model_path+'valid_data.bc')\n",
    "trn_labels = load_array(model_path+'trn_labels.bc')\n",
    "val_labels = load_array(model_path+'val_labels.bc')\n",
    "val_labels = onehot(val_labels)\n",
    "trn_labels = onehot(trn_labels)\n",
    "\n",
    "test_data = load_array(model_path+'test_data.bc')\n",
    "test_data = test_data.transpose((0,3,1,2))\n",
    "\n",
    "from vgg16bn import Vgg16BN\n",
    "model = vgg_ft_bn(8)\n",
    "\n",
    "model.compile(optimizer=Adam(1e-3),\n",
    "       loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.load_weights(data_path+'results/ft1.h5')\n",
    "\n",
    "conv_layers,fc_layers = split_at(model, Convolution2D)\n",
    "conv_model = Sequential(conv_layers)\n",
    "#load features\n",
    "conv_feat = load_array(data_path+'results/conv_feat.dat')\n",
    "conv_val_feat = load_array(data_path+'results/conv_val_feat.dat')\n",
    "conv_test_feat = load_array(data_path+'results/conv_test_feat.dat')\n",
    "\n",
    "model.summary()\n",
    "for layer in model.layers:\n",
    "    print(layer.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nf=128; p=0.\n",
    "def get_lrg_layers():\n",
    "    return [\n",
    "        BatchNormalization(axis=1, input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D((1,2)),\n",
    "        Convolution2D(8,3,3, border_mode='same'),\n",
    "        Dropout(p),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Activation('softmax')\n",
    "    ] \n",
    "\n",
    "fcn_model = Sequential(get_lrg_layers())\n",
    "# fcn_model.summary()\n",
    "fcn_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# fcn_model.fit(conv_feat, trn_labels, batch_size=6, nb_epoch=3, validation_data=(conv_val_feat, val_labels))\n",
    "fcn_model.load_weights(model_path+'/fcn_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 5s      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.30357783174514769, 0.93799999904632569]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcn_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "fcn_model.evaluate(conv_val_feat, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid dimensions for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-b9c360fd7bda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# print(inp)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# np.round(fcn_model.predict(inp)[0],2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m# cm = get_cm(inp, 0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# plt.imshow(cm, cmap=\"cool\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mh/.local/lib/python3.5/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3156\u001b[0m                         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3157\u001b[0m                         \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3158\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m   3159\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3160\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mh/.local/lib/python3.5/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1890\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1891\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1892\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1893\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1894\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mh/.local/lib/python3.5/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5116\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5118\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5119\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mh/.local/lib/python3.5/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    547\u001b[0m         if (self._A.ndim not in (2, 3) or\n\u001b[1;32m    548\u001b[0m                 (self._A.ndim == 3 and self._A.shape[-1] not in (3, 4))):\n\u001b[0;32m--> 549\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_imcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid dimensions for image data"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGCQ1/wMKpFHVdp3xCwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdee8b383c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l = fcn_model.layers\n",
    "\n",
    "conv_fn = K.function([l[0].input, K.learning_phase()], [l[-4].output])\n",
    "def get_cm(imp, label):\n",
    "    conv = conv_fn([imp,0])[0, label]\n",
    "    return scipy.misc.imresize(conv, (224,224), interp='nearest')\n",
    "inp = np.expand_dims(conv_val_feat[0], 2)\n",
    "# print(inp)\n",
    "# np.round(fcn_model.predict(inp)[0],2)\n",
    "plt.imshow(to_plot(val_data[0]))\n",
    "# cm = get_cm(inp, 0)\n",
    "# plt.imshow(cm, cmap=\"cool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing filter 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (512,14,14) (3,1,1) (512,14,14) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-8c5f16917802>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# decode the resulting input image and add it to the list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_img_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mkept_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-8c5f16917802>\u001b[0m in \u001b[0;36mdeprocess\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# util function to convert a tensor into a valid image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdeprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mMEAN_VALUES\u001b[0m \u001b[0;31m# Add VGG16 mean values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Change from BGR to RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (512,14,14) (3,1,1) (512,14,14) "
     ]
    }
   ],
   "source": [
    "MEAN_VALUES = np.array([103.939, 116.779, 123.68]).reshape((3,1,1))\n",
    "\n",
    "# util function to convert a tensor into a valid image\n",
    "def deprocess(x):\n",
    "    x += MEAN_VALUES # Add VGG16 mean values\n",
    " \n",
    "    x = x[::-1, :, :] # Change from BGR to RGB\n",
    "    x = x.transpose((1, 2, 0)) # Change from (Channel,Height,Width) to (Height,Width,Channel)\n",
    "    \n",
    "    x = np.clip(x, 0, 255).astype('uint8') #clip in [0;255] and convert to int\n",
    "    return x\n",
    " \n",
    "\n",
    "input_img = fcn_model.layers[0].input\n",
    "layer_output = fcn_model.layers[-4].output\n",
    "\n",
    "kept_images = []\n",
    " \n",
    "# Update coefficient\n",
    "learning_rate = 500.\n",
    " \n",
    "for class_index in [0, 1, 2, 3]: #130 flamingo, 351 hartebeest, 736 pool table, 850 teddy bear\n",
    "    print('Processing filter %d' % class_index)\n",
    "    start_time = time.time()\n",
    " \n",
    "    # The loss is the activation of the neuron for the chosen class\n",
    "    loss = layer_output[0, class_index]\n",
    " \n",
    "    # we compute the gradient of the input picture wrt this loss\n",
    "    grads = K.gradients(loss, input_img)[0]\n",
    " \n",
    "    # this function returns the loss and grads given the input picture\n",
    "    # also add a flag to disable the learning phase (in our case dropout)\n",
    "    iterate = K.function([input_img, K.learning_phase()], [loss, grads])\n",
    " \n",
    "    np.random.seed(1337)  # for reproducibility\n",
    "    # we start from a gray image with some random noise\n",
    "    input_img_data = np.random.normal(0, 10, (1,) + fcn_model.input_shape[1:]) # (1,) for batch axis\n",
    " \n",
    "    # we run gradient ascent for 1000 steps\n",
    "    for i in range(1000):\n",
    "        loss_value, grads_value = iterate([input_img_data, 0]) # 0 for test phase\n",
    "        input_img_data += grads_value * learning_rate # Apply gradient to image\n",
    " \n",
    "        #print('Current loss value:', loss_value)\n",
    " \n",
    "    # decode the resulting input image and add it to the list\n",
    "    img = deprocess(input_img_data[0])\n",
    "    kept_images.append((img, loss_value))\n",
    "    end_time = time.time()\n",
    "#     print('Filter %d processed in %ds' % (class_index, end_time - start_time))\n",
    "#Compute the size of the grid\n",
    "n = int(np.ceil(np.sqrt(len(kept_images))))\n",
    " \n",
    "# build a black picture with enough space for the kept_images\n",
    "img_height = model.input_shape[2]\n",
    "img_width = model.input_shape[3]\n",
    "margin = 5\n",
    "height = n * img_height + (n - 1) * margin\n",
    "width = n * img_width + (n - 1) * margin\n",
    "stitched_res = np.zeros((height, width, 3))\n",
    " \n",
    "# fill the picture with our saved filters\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        if len(kept_images) <= i * n + j:\n",
    "            break\n",
    "        img, loss = kept_images[i * n + j]\n",
    "        stitched_res[(img_height + margin) * i: (img_height + margin) * i + img_height,\n",
    "                         (img_width + margin) * j: (img_width + margin) * j + img_width, :] = img\n",
    "\n",
    "scipy.misc.toimage(stitched_res, cmin=0, cmax=255).save('naive_results_%dx%d.png' % (n, n)) # Do not use scipy.misc.imsave because it will normalize the image pixel value between 0 and 255\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3277, 512, 14, 14)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conv_feat = conv_feat.transpose((0,2,1,3))\n",
    "conv_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-0b36871e3ac6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# Generate three different images of the same output index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m vis_images = [visualize_activation(model, layer_idx, filter_indices=idx,  max_iter=500)\n\u001b[0;32m---> 56\u001b[0;31m               for idx in [20, 20, 20]]\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstitch_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvis_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-87-0b36871e3ac6>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# Generate three different images of the same output index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m vis_images = [visualize_activation(model, layer_idx, filter_indices=idx,  max_iter=500)\n\u001b[0;32m---> 56\u001b[0;31m               for idx in [20, 20, 20]]\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstitch_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvis_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mh/.local/lib/python3.5/site-packages/vis/visualization.py\u001b[0m in \u001b[0;36mvisualize_activation\u001b[0;34m(img, layer, filter_indices, seed_img, max_iter, act_max_weight, lp_norm_weight, tv_weight, verbose, show_filter_idx_text, idx_label_map, cols)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# from keras.preprocessing.image import img_to_array\n",
    "# from vis.utils import utils\n",
    "# from vis.utils.vggnet import VGG16\n",
    "# from vis.visualization import visualize_saliency\n",
    "\n",
    "\n",
    "# # The name of the layer we want to visualize\n",
    "# # (see model definition in vggnet.py)\n",
    "# layer_name = 'convolution2d_13'\n",
    "# layer_idx = [idx for idx, layer in enumerate(model.layers) if layer.name == layer_name][0]\n",
    "\n",
    "# # Images corresponding to tiger, penguin, dumbbell, speedboat, spider\n",
    "# image_paths = [\n",
    "#     data_path+'/train/LAG/img_00091.jpg'\n",
    "# ]\n",
    "\n",
    "\n",
    "# heatmaps = []\n",
    "# for path in image_paths:\n",
    "#     # Predict the corresponding class for use in `visualize_saliency`.\n",
    "#     seed_img = utils.load_img(path, target_size=(14, 14))\n",
    "#     pred_class = np.argmax(fcn_model.predict(np.array([img_to_array(conv_feat[2])])))\n",
    "\n",
    "#     # Here we are asking it to show attention such that prob of `pred_class` is maximized.\n",
    "#     heatmap = visualize_saliency(fcn_model, layer_idx, [pred_class], seed_img, )\n",
    "#     heatmaps.append(heatmap)\n",
    "\n",
    "# cv2.imshow(\"Saliency map\", utils.stitch_images(heatmaps))\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# Build the VGG16 network with ImageNet weights\n",
    "# model = VGG16(weights='imagenet', include_top=True)\n",
    "# print('Model loaded.')\n",
    "\n",
    "import cv2\n",
    "\n",
    "from vis.utils.utils import stitch_images\n",
    "from vis.utils.vggnet import VGG16\n",
    "from vis.visualization import visualize_activation\n",
    "\n",
    "# The name of the layer we want to visualize\n",
    "# (see model definition in vggnet.py)\n",
    "layer_name = 'predictions'\n",
    "# for idx, layer in enumerate(model.layers):\n",
    "#     print(idx)\n",
    "#     print(layer)\n",
    "# layer_idx = [idx for idx, layer in enumerate(model.layers) if layer.name == layer_name][0]\n",
    "\n",
    "layer_idx = -4\n",
    "\n",
    "# Generate three different images of the same output index.\n",
    "vis_images = [visualize_activation(model, layer_idx, filter_indices=idx,  max_iter=500)\n",
    "              for idx in [20, 20, 20]]\n",
    "cv2.imshow(layer_name, stitch_images(vis_images))\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'losses'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d70c4a26c838>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstitch_images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvggnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualize_activation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_num_filters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# The name of the layer we want to visualize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mh/.local/lib/python3.5/site-packages/vis/visualization.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mActivationMaximization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mregularizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTotalVariation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLPNorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'losses'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from vis.utils.utils import stitch_images\n",
    "from vis.utils.vggnet import VGG16\n",
    "from vis.visualization import visualize_activation, get_num_filters\n",
    "\n",
    "# The name of the layer we want to visualize\n",
    "# (see model definition in vggnet.py)\n",
    "layer_name = 'convolution2d_13'\n",
    "layer_idx = [idx for idx, layer in enumerate(model.layers) if layer.name == layer_name][0]\n",
    "\n",
    "# Visualize all filters in this layer.\n",
    "filters = np.arange(get_num_filters(model.layers[layer_idx]))\n",
    "\n",
    "# Generate input image for each filter. Here `text` field is used to overlay `filter_value` on top of the image.\n",
    "vis_images = [visualize_activation(model, layer_idx, filter_indices=idx, text=str(idx))\n",
    "              for idx in filters]\n",
    "\n",
    "# Generate stitched image pallette with 10 cols.\n",
    "cv2.imshow(layer_name, stitch_images(vis_images, cols=8))\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.0465, -0.02  ,  0.0168, ..., -0.0228, -0.0025, -0.0278],\n",
      "       [-0.0218,  0.0289,  0.0278, ..., -0.0155,  0.0191,  0.02  ],\n",
      "       [-0.01  , -0.0256, -0.0342, ..., -0.0358, -0.0007,  0.0175],\n",
      "       ..., \n",
      "       [ 0.0573, -0.0144, -0.0079, ...,  0.0832, -0.0315, -0.055 ],\n",
      "       [ 0.0242, -0.0381,  0.0692, ...,  0.004 , -0.0363, -0.0567],\n",
      "       [ 0.0114, -0.0155, -0.034 , ...,  0.0216,  0.0229, -0.041 ]], dtype=float32), array([ 0.0493, -0.0374, -0.0348, -0.0458, -0.0031, -0.0265, -0.043 ,  0.0383], dtype=float32)]\n",
      "(224, 3, 224)\n",
      "(1, 224, 3, 224)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (1, 224, 3, 224) for Tensor 'lambda_input_1:0', which has shape '(?, 3, 224, 224)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-c5ad2d2c0a96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# plt.imshow(to_plot(val[0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cool\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-c5ad2d2c0a96>\u001b[0m in \u001b[0;36mget_cm\u001b[0;34m(imp, label)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconv_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m360\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtrn_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrn_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1941\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 1943\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   1944\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mh/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mh/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    942\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m    945\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (1, 224, 3, 224) for Tensor 'lambda_input_1:0', which has shape '(?, 3, 224, 224)'"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "l = model.layers\n",
    "print(l[-1].get_weights())\n",
    "conv_fn = K.function([l[0].input, K.learning_phase()], [l[-4].output])\n",
    "def get_cm(imp, label):\n",
    "    conv = conv_fn([imp,0])[0, label]\n",
    "    return scipy.misc.imresize(conv, (360,640), interp='nearest')\n",
    "trn_data = trn_data.transpose((0,2,1,3))\n",
    "print(trn_data[0].shape)\n",
    "inp = np.expand_dims(trn_data[0], 0)\n",
    "print(inp.shape)\n",
    "\n",
    "# print(np.round(model.predict(inp)[0],2))\n",
    "# plt.imshow(to_plot(val[0]))\n",
    "\n",
    "cm = get_cm(inp, 0)\n",
    "plt.imshow(cm, cmap=\"cool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W shape :  []\n",
      "W shape :  (0,)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-dc4c8a423bd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'conv1 weights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mnice_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_mosaic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-46074e99fedb>\u001b[0m in \u001b[0;36mmake_mosaic\u001b[0;34m(imgs, nrows, ncols, border)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mimshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     mosaic = ma.masked_all((nrows * imshape[0] + (nrows - 1) * border,\n\u001b[0m\u001b[1;32m     12\u001b[0m                             ncols * imshape[1] + (ncols - 1) * border),\n\u001b[1;32m     13\u001b[0m                             dtype=np.float32)\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3IAAANeCAYAAABXuTysAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGhQWEN8D3AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa367a069b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "import pylab as pl\n",
    "import matplotlib.cm as cm\n",
    "# l = model.layers\n",
    "# Visualize weights\n",
    "W = model.layers[1].get_weights()\n",
    "print(\"W shape : \", W)\n",
    "W = np.squeeze(W)\n",
    "print(\"W shape : \", W.shape)\n",
    "\n",
    "pl.figure(figsize=(15, 15))\n",
    "pl.title('conv1 weights')\n",
    "nice_imshow(pl.gca(), make_mosaic(W, 6, 6), cmap=cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# utility functions\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def nice_imshow(ax, data, vmin=None, vmax=None, cmap=None):\n",
    "    \"\"\"Wrapper around pl.imshow\"\"\"\n",
    "    if cmap is None:\n",
    "        cmap = cm.jet\n",
    "    if vmin is None:\n",
    "        vmin = data.min()\n",
    "    if vmax is None:\n",
    "        vmax = data.max()\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    im = ax.imshow(data, vmin=vmin, vmax=vmax, interpolation='nearest', cmap=cmap)\n",
    "    pl.colorbar(im, cax=cax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy.ma as ma\n",
    "def make_mosaic(imgs, nrows, ncols, border=1):\n",
    "    \"\"\"\n",
    "    Given a set of images with all the same shape, makes a\n",
    "    mosaic with nrows and ncols\n",
    "    \"\"\"\n",
    "    nimgs = imgs.shape[0]\n",
    "    imshape = imgs.shape[1:]\n",
    "    \n",
    "    mosaic = ma.masked_all((nrows * imshape[0] + (nrows - 1) * border,\n",
    "                            ncols * imshape[1] + (ncols - 1) * border),\n",
    "                            dtype=np.float32)\n",
    "    \n",
    "    paddedh = imshape[0] + border\n",
    "    paddedw = imshape[1] + border\n",
    "    for i in xrange(nimgs):\n",
    "        row = int(np.floor(i / ncols))\n",
    "        col = i % ncols\n",
    "        \n",
    "        mosaic[row * paddedh:row * paddedh + imshape[0],\n",
    "               col * paddedw:col * paddedw + imshape[1]] = imgs[i]\n",
    "    return mosaic\n",
    "\n",
    "#pl.imshow(make_mosaic(np.random.random((9, 10, 10)), 3, 3, border=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
