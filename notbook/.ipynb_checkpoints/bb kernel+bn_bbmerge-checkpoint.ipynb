{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3277 images belonging to 9 classes.\n",
      "Found 500 images belonging to 8 classes.\n",
      "Found 1000 images belonging to 1 classes.\n",
      "Found 3277 images belonging to 9 classes.\n",
      "Found 500 images belonging to 8 classes.\n",
      "Found 1000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Rather than importing everything manually, we'll make things easy\n",
    "#   and load them all in utils.py, and just import them from there.\n",
    "%matplotlib inline\n",
    "import utils;\n",
    "from utils import *\n",
    "import time\n",
    "from __future__ import division, print_function\n",
    "import sys\n",
    "sys.path.insert(1, '/home/mh/opencv-master/build/lib/python3')\n",
    "import cv2\n",
    "import glob\n",
    "from keras.optimizers import Adadelta\n",
    "\n",
    "data_path = '/home/mh/ws/fish_challenge/input/'\n",
    "model_path = '/home/mh/ws/fish_challenge/input/models/'\n",
    "batch_size=32\n",
    "\n",
    "batches = get_batches(data_path+'train', batch_size=batch_size)\n",
    "val_batches = get_batches(data_path+'valid', batch_size=batch_size*2, shuffle=False)\n",
    "test_filenames = get_batches(data_path+'test', batch_size=batch_size).filenames\n",
    "\n",
    "(val_classes, trn_classes, val_labels, trn_labels, \n",
    "    val_filenames, filenames, test_filenames) = get_classes(data_path)\n",
    "\n",
    "raw_filenames = [f.split('/')[-1] for f in filenames]\n",
    "raw_test_filenames = [f.split('/')[-1] for f in test_filenames]\n",
    "raw_val_filenames = [f.split('/')[-1] for f in val_filenames]\n",
    "\n",
    "## Load data.\n",
    "trn_data = load_array(model_path+'train_data.bc')\n",
    "val_data = load_array(model_path+'valid_data.bc')\n",
    "trn_labels = load_array(model_path+'trn_labels.bc')\n",
    "val_labels = load_array(model_path+'val_labels.bc')\n",
    "val_labels = onehot(val_labels)\n",
    "trn_labels = onehot(trn_labels)\n",
    "\n",
    "test_data = load_array(model_path+'test_data.bc')\n",
    "test_data = test_data.transpose((0,3,1,2))\n",
    "\n",
    "from vgg16bn import Vgg16BN\n",
    "model = vgg_ft_bn(8)\n",
    "\n",
    "model.compile(optimizer=Adam(1e-3),\n",
    "       loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.load_weights(data_path+'results/ft1.h5')\n",
    "\n",
    "conv_layers,fc_layers = split_at(model, Convolution2D)\n",
    "conv_model = Sequential(conv_layers)\n",
    "#load features\n",
    "conv_feat = load_array(data_path+'results/conv_feat.dat')\n",
    "conv_val_feat = load_array(data_path+'results/conv_val_feat.dat')\n",
    "conv_test_feat = load_array(data_path+'results/conv_test_feat.dat')\n",
    "\n",
    "def get_bn_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        BatchNormalization(axis=1),\n",
    "        Dropout(p/4),\n",
    "        Flatten(),\n",
    "        Dense(512,activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p/2),\n",
    "        Dense(512,activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p/2),\n",
    "        Dense(8,activation='softmax')\n",
    "    ]\n",
    "\n",
    "p=0.6\n",
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "bn_model.load_weights(data_path+'models/conv_512_6.h5')\n",
    "\n",
    "import ujson as json\n",
    "anno_classes = ['alb', 'bet', 'dol', 'lag', 'other', 'shark', 'yft']\n",
    "bb_json = {}\n",
    "for c in anno_classes:\n",
    "    j = json.load(open('{}/boxes/{}.json'.format(data_path, c), 'r'))\n",
    "    for l in j:\n",
    "        if 'annotations' in l.keys() and len(l['annotations'])>0:\n",
    "            bb_json[l['filename'].split('/')[-1]] = sorted(\n",
    "                l['annotations'], key=lambda x: x['height']*x['width'])[-1]\n",
    "\n",
    "sizes = [PIL.Image.open(data_path+'train/'+f).size for f in filenames]\n",
    "id2size = list(set(sizes))\n",
    "size2id = {o:i for i,o in enumerate(id2size)}\n",
    "raw_val_sizes = [PIL.Image.open(data_path+'valid/'+f).size for f in val_filenames]\n",
    "\n",
    "file2idx = {o:i for i,o in enumerate(raw_filenames)}\n",
    "val_file2idx = {o:i for i,o in enumerate(raw_val_filenames)}\n",
    "empty_bbox = {'height': 0., 'width': 0., 'x': 0., 'y': 0.}\n",
    "for f in raw_filenames:\n",
    "    if not f in bb_json.keys(): bb_json[f] = empty_bbox\n",
    "for f in raw_val_filenames:\n",
    "    if not f in bb_json.keys(): bb_json[f] = empty_bbox\n",
    "\n",
    "bb_params = ['height', 'width', 'x', 'y']\n",
    "def convert_bb(bb, size):\n",
    "    bb = [bb[p] for p in bb_params]\n",
    "    bb[0]= bb[0]*(224/size[0])\n",
    "    bb[1]= bb[1]*(224/size[1])\n",
    "    bb[2]= max(bb[2]*(224/size[0]),0)\n",
    "    bb[3]= max(bb[3]*(224/size[1]),0)\n",
    "    return bb\n",
    "val_bbox = np.stack([convert_bb(bb_json[f], s) \n",
    "                   for f,s in zip(raw_val_filenames, raw_val_sizes)]).astype(np.float32)\n",
    "\n",
    "trn_bbox = np.stack([convert_bb(bb_json[f],s) for f,s in zip(raw_filenames, sizes)]).astype(np.float32)\n",
    "\n",
    "# val = get_data(data_path+'valid', (360,640))\n",
    "\n",
    "def create_rect(bb, color='red'):\n",
    "    plot.Rectangle((bb[3],bb[2]),bb[1],bb[0],color=color, fill=False, lw=3)\n",
    "    \n",
    "def show_bb(i):\n",
    "    bb = val_bbox[i]\n",
    "    print(cv2.resize(val,(360,640)).shape)\n",
    "    img = val[i]\n",
    "    plot(img)\n",
    "    plt.gca().add_patch(create_rect(bb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class': 'rect',\n",
       " 'height': 390.00000000000097,\n",
       " 'width': 444.00000000000114,\n",
       " 'x': 528.0000000000013,\n",
       " 'y': 121.00000000000028}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb_json['img_00091.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  30.597    95.6293  141.3878   55.7107]\n",
      " [  32.5702   92.749   136.0286   60.2606]\n",
      " [  32.025    36.7111  126.35    133.4667]\n",
      " ..., \n",
      " [  22.575    73.1111   67.375   124.4444]\n",
      " [  56.7297   52.1593   34.0794   24.5777]\n",
      " [  36.1574  104.6209    0.8312   87.2432]]\n",
      "[  32.5702   92.749   136.0286   60.2606]\n"
     ]
    }
   ],
   "source": [
    "x = 600\n",
    "\n",
    "# for b in trn_bbox:\n",
    "#     x = min(b[1]*b[2],x)\n",
    "\n",
    "print(trn_bbox)\n",
    "print(trn_bbox[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "inp = Input(conv_layers[-1].output_shape[1:])\n",
    "x = MaxPooling2D()(inp)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = Dropout(p/4)(x)\n",
    "x = Flatten()(x)\n",
    "i = x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(p)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(p/2)(x)\n",
    "x_bb = Dense(4, name='bb')(x)\n",
    "x_class = Dense(8, activation='softmax', name='class')(x)\n",
    "\n",
    "model = Model([inp], [x_bb, x_class])\n",
    "model.compile(Adam(lr=0.001), loss=['mse', 'categorical_crossentropy'], metrics=['accuracy'],\n",
    "             loss_weights=[.001, 1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 512, 14, 14)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 512, 14, 14)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_7 (MaxPooling2D)    (None, 512, 7, 7)     0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_6 (BatchNorma (None, 512, 7, 7)     2048        maxpooling2d_7[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 512, 7, 7)     0           batchnormalization_6[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 25088)         0           dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 512)           12845568    flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_7 (BatchNorma (None, 512)           2048        dense_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 512)           0           batchnormalization_7[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 512)           262656      dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_8 (BatchNorma (None, 512)           2048        dense_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 512)           0           batchnormalization_8[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "bb (Dense)                       (None, 4)             2052        dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "class (Dense)                    (None, 8)             4104        dropout_8[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 13,120,524\n",
      "Trainable params: 13,117,452\n",
      "Non-trainable params: 3,072\n",
      "____________________________________________________________________________________________________\n",
      "[  9.9770e-01   9.5691e-05   6.9905e-05   1.3177e-05   6.2169e-05   1.9886e-03   3.6950e-05\n",
      "   3.0624e-05]\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(data_path+'models/bn_anno_24epochs.h5')\n",
    "\n",
    "def do_clip(arr, mx): return np.clip(arr, (1-mx)/7, mx)\n",
    "\n",
    "print(conv_test_feat.shape)\n",
    "model.summary()\n",
    "boxes, preds = model.predict(conv_test_feat, batch_size=8)\n",
    "print(preds[0])\n",
    "\n",
    "# preds = np.array(preds)\n",
    "preds = do_clip(preds,0.83)\n",
    "# subm = preds\n",
    "\n",
    "subm_name = data_path+'results/subm_24epoch_bb_clipping_0.83.gz'\n",
    "\n",
    "# classes = sorted(batches.class_indices, key=batches.class_indices.get)\n",
    "classes = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n",
    "\n",
    "submission = pd.DataFrame(preds, columns=classes)\n",
    "submission.insert(0, 'image', raw_test_filenames)\n",
    "submission.head()\n",
    "submission.to_csv(subm_name, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Merge Models\n",
    "def merge_several_folds_mean(data, num):\n",
    "    a = np.array(data[0])\n",
    "    for i in range(1, num):\n",
    "        a += np.array(data[i])\n",
    "    a /= num\n",
    "    return a.tolist()\n",
    "\n",
    "yfull_test=[]\n",
    "yfull_test.append(preds)\n",
    "preds_bn_vgg = bn_model.predict(conv_test_feat, batch_size=32)\n",
    "yfull_test.append(preds_bn_vgg)\n",
    "\n",
    "merged_preds = merge_several_folds_mean(yfull_test, 2)\n",
    "\n",
    "# preds = np.array(preds)\n",
    "preds = do_clip(merged_preds,0.84)\n",
    "# subm = preds\n",
    "\n",
    "subm_name = data_path+'results/subm_24epoch_bb+bn_clipping_0.83.gz'\n",
    "\n",
    "# classes = sorted(batches.class_indices, key=batches.class_indices.get)\n",
    "classes = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n",
    "\n",
    "submission = pd.DataFrame(preds, columns=classes)\n",
    "submission.insert(0, 'image', raw_test_filenames)\n",
    "submission.head()\n",
    "submission.to_csv(subm_name, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'ravel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-83a72eabcb85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_neigbours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;31m#Apply rules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mR1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'ravel'"
     ]
    }
   ],
   "source": [
    "pattern =np.array([[0,0,0,0,0,0],\n",
    "                  [0,0,0,1,0,0],\n",
    "                  [0,1,0,1,0,0],\n",
    "                  [0,0,1,1,0,0],\n",
    "                  [0,0,0,0,0,0],\n",
    "                  [0,0,0,0,0,0]])\n",
    "def compute_neigbours(Z):\n",
    "    shape = len(Z), len(Z[0])\n",
    "    N  = [[0,]*(shape[0])  for i in range(shape[1])]\n",
    "    for x in range(1,shape[0]-1):\n",
    "        for y in range(1,shape[1]-1):\n",
    "            N[x][y] = Z[x-1][y-1]+Z[x][y-1]+Z[x+1][y-1] \\\n",
    "                    + Z[x-1][y]            +Z[x+1][y]   \\\n",
    "                    + Z[x-1][y+1]+Z[x][y+1]+Z[x+1][y+1]\n",
    "    return N\n",
    "N = compute_neigbours(pattern)\n",
    "#Apply rules\n",
    "R1 = np.argwhere( (pattern==1) & (N < 2) )\n",
    "R2 = np.argwhere( (pattern==1) & (N > 3) )\n",
    "R3 = np.argwhere( (pattern==1) & ((N==2) | (N==3)) )\n",
    "R4 = np.argwhere( (pattern==0) & (N==3) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'selective_search'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2d5abb6e8f71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mselectivesearch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastronaut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimg_lbl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselectivesearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselective_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mh/.local/lib/python3.5/site-packages/selectivesearch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mselectivesearch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mselective_search\u001b[0m  \u001b[0;31m# NOQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'selective_search'"
     ]
    }
   ],
   "source": [
    "import skimage.data\n",
    "import selectivesearch\n",
    "\n",
    "img = skimage.data.astronaut()\n",
    "img_lbl, regions = selectivesearch.selective_search(img, scale=500, sigma=0.9, min_size=10)\n",
    "regions[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
